{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "V1_seperatedDS_data_processing.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOIjcSNzqmfjiMmSp74C8+t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SupermarketAutomationAI/data_processing/blob/main/V1_seperatedDS_data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lofQ_cinn2GP"
      },
      "source": [
        "# Data Loading, Splitting, and Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnpKb-WKLSfv"
      },
      "source": [
        "This Jupyter notebook contains the data processing for the first version of data processing. The format of this version is as follows:\n",
        "\n",
        "/SupermarketAutomationAI_Dataset_V1\n",
        "```\n",
        "/train\n",
        "  Multiple Bananas\n",
        "  One Banana\n",
        "  .\n",
        "  .\n",
        "  .\n",
        "/val\n",
        "  Multiple Bananas\n",
        "  One Banana\n",
        "  .\n",
        "  .\n",
        "  .\n",
        "/test\n",
        "  Multiple Bananas\n",
        "  One Banana\n",
        "  .\n",
        "  .\n",
        "  .\n",
        "```\n",
        "Where each of the above subdirectories in train, val, and test are their own class. In this version, there are 14 classes to classify.\n",
        "\n",
        "Classes: \n",
        "\n",
        "['Multiple Bananas', 'Multiple Fuji Apples', 'Multiple Gala Apples', 'Multiple Golden Delicious Apples', 'Multiple Granny Smith Apples', 'Multiple Oranges', 'Multiple Red Delicious Apples', 'One Banana', 'One Fuji Apple', 'One Gala Apple', 'One Golden Delicious Apple', 'One Granny Smith Apple', 'One Orange', 'One Red Delicious Apple']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq3gSdZKhKcf"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w72qsUlSn9ux",
        "outputId": "d0543209-1eed-4ce4-90c8-f188f0fa80ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3sFb9inopsm"
      },
      "source": [
        "! unzip '/content/drive/My Drive/APS360 Project/Dataset Zip Files/SupermarketAutomationAI_Dataset_V1' -d '/root/datasets'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfBIpArgOHfI"
      },
      "source": [
        "# Clean the data, remove \"._\" from file names\n",
        "import os\n",
        "from glob import glob\n",
        "parent_dir = \"/root/datasets/SupermarketAutomationAI_Dataset_V1\"\n",
        "classes = ['Multiple Bananas', 'Multiple Fuji Apples', 'Multiple Gala Apples', 'Multiple Golden Delicious Apples', \n",
        "           'Multiple Granny Smith Apples', 'Multiple Oranges', 'Multiple Red Delicious Apples', 'One Banana', \n",
        "           'One Fuji Apple', 'One Gala Apple', 'One Golden Delicious Apple', 'One Granny Smith Apple', 'One Orange', \n",
        "           'One Red Delicious Apple']\n",
        "\n",
        "for cat in classes:\n",
        "    path = parent_dir + '/' + cat\n",
        "    invalid_files = glob(os.path.join(path,\"._*\"))\n",
        "    for file_ in invalid_files:\n",
        "        os.rename(file_, os.path.join(path,file_.split('/')[-1].replace(\"._\",\"\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IrjH_sko_bD"
      },
      "source": [
        "## Split the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SriTVEYqWGAR"
      },
      "source": [
        "# Import the necessary libraries\n",
        "import json\n",
        "import os\n",
        "import math\n",
        "import shutil"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-do21bIZWK2M"
      },
      "source": [
        "# create data directory and move all images into it\n",
        "parent_dir = \"/root/datasets/SupermarketAutomationAI_Dataset_V1\"\n",
        "os.chdir(parent_dir)\n",
        "category_list = list(filter(lambda x: os.path.isdir(x), os.listdir()))\n",
        "data_dir = parent_dir + '/' + \"data\"\n",
        "os.mkdir(data_dir, 755)\n",
        "for category in category_list:\n",
        "    cat_dir = parent_dir + '/' + category\n",
        "    shutil.move(cat_dir, data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4iELB8cImGE"
      },
      "source": [
        "train_split = 0.6\n",
        "\n",
        "dataset_dirs= ['train','val','test']\n",
        "for dsdirs in dataset_dirs:\n",
        " path = parent_dir + '/'+ dsdirs\n",
        " os.mkdir( path,755 )\n",
        "\n",
        "for category in category_list: \n",
        "    src_path = parent_dir + '/data/' + category\n",
        "    train_dir = parent_dir + '/train/' + category + '/'\n",
        "    val_dir = parent_dir + '/val/' + category + '/'\n",
        "    test_dir = parent_dir + '/test/' + category + '/'\n",
        "    \n",
        "    os.mkdir(train_dir, 755 )\n",
        "    os.mkdir(val_dir, 755)\n",
        "    os.mkdir(test_dir, 755)\n",
        "\n",
        "    #get files' names list from respective directories\n",
        "    os.chdir(src_path)\n",
        "    files = [f for f in os.listdir() if os.path.isfile(f)]\n",
        "\n",
        "    #get training, testing and validation files count\n",
        "    train_count = math.ceil(train_split*len(files))\n",
        "    valid_count = int((len(files)-train_count)/2)\n",
        "    test_count = valid_count\n",
        "\n",
        "    #get files to segragate for train,test and validation data set\n",
        "    train_data_list = files[0: train_count-1]\n",
        "    valid_data_list = files[train_count:train_count+valid_count-1] \n",
        "    test_data_list = files[train_count+valid_count:]\n",
        "\n",
        "\n",
        "    for train_data in train_data_list:\n",
        "        train_path = src_path + '/' + train_data\n",
        "        shutil.move(train_path,train_dir)\n",
        "\n",
        "    for valid_data in valid_data_list:\n",
        "        valid_path = src_path + '/' + valid_data\n",
        "        shutil.move(valid_path,val_dir)\n",
        "\n",
        "    for test_data in test_data_list:\n",
        "        test_path = src_path + '/' + test_data\n",
        "        shutil.move(test_path,test_dir)\n",
        "\n",
        "    # Move any files that are left behind into the training directory\n",
        "    os.chdir(src_path)\n",
        "    files = [f for f in os.listdir() if os.path.isfile(f)]\n",
        "    for img_left_behind in files:\n",
        "        img_path = src_path + '/' + img_left_behind\n",
        "        shutil.move(img_path, train_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2JbM8qchO3m"
      },
      "source": [
        "## Preprocess data into Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Enhl8HtCizZb"
      },
      "source": [
        "# import needed libraries for this section\n",
        "import torch\n",
        "from torchvision import datasets, transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxzhzA1Wf9Y7",
        "outputId": "4f6022d9-786a-4ec1-c95b-b4af18524086",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# define the locations of the training and validation data\n",
        "train_dir = os.path.join(parent_dir, 'train/')\n",
        "val_dir = os.path.join(parent_dir, 'val/')\n",
        "test_dir = os.path.join(parent_dir, 'test/')\n",
        "\n",
        "# define a list of all classes that the model will be trained with\n",
        "\n",
        "# List different classes: 14 currently\n",
        "classes = ['Multiple Bananas', 'Multiple Fuji Apples', 'Multiple Gala Apples', 'Multiple Golden Delicious Apples', \n",
        "           'Multiple Granny Smith Apples', 'Multiple Oranges', 'Multiple Red Delicious Apples',\n",
        "           'One Banana', 'One Fuji Apple', 'One Gala Apple', 'One Golden Delicious Apple',\n",
        "           'One Granny Smith Apple', 'One Orange', 'One Red Delicious Apple']\n",
        "\n",
        "# three possible transforms, will test each to see which gives better results\n",
        "data_CC_transform = transforms.Compose([transforms.CenterCrop([224,224]), transforms.ToTensor()])\n",
        "\n",
        "# apply the transforms to the data\n",
        "train_data = datasets.ImageFolder(train_dir, transform=data_CC_transform)\n",
        "val_data = datasets.ImageFolder(val_dir, transform=data_CC_transform)\n",
        "test_data = datasets.ImageFolder(test_dir, transform=data_CC_transform)\n",
        "\n",
        "# print the amount of data in both training and validation sets\n",
        "print(\"Amount of training data: \", len(train_data))\n",
        "print(\"Amount of validation data: \", len(val_data))\n",
        "print(\"Amount of test data: \", len(test_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of training data:  6936\n",
            "Amount of validation data:  2287\n",
            "Amount of test data:  2305\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CBUeZL8jTDp"
      },
      "source": [
        "# Model Building, Training, and Testing"
      ]
    }
  ]
}